{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e7824c-ca70-40a7-8f29-6c4127ae3a23",
   "metadata": {},
   "source": [
    "# Stock and ETFs analysis and strategy\n",
    "\n",
    "#### Author: Matteo Caorsi\n",
    "\n",
    "The goal of this simply otebook is to go through a few very basic analysis on how and on what to invest.\n",
    "\n",
    "There are some **assumptions** made in this model:\n",
    " 1. We do not like risks and thus we prefer to ot lose than to have a chance of gaining a lot of money on a bet\n",
    " 2. We do not do HFT. We do long term strategies that do not require constant surveillance of the stock market\n",
    " 3. The future will have similar stochastic properties as the past; note that we do not imply that financial markets are stationary (which are clearly not), but rather that the global market will continuously grow\n",
    " \n",
    "The analysis is divided into two main sections:\n",
    " 1. Stock market analysis and simulations\n",
    " 2. ETFs analysis and simulations\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a449d9-e31a-4efc-88f2-2736ab76617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing the main tools\n",
    "# type hinting\n",
    "from numbers import Number\n",
    "from typing import Tuple, Callable, List\n",
    "\n",
    "# data\n",
    "from get_all_tickers import get_tickers as gt\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os.path\n",
    "import random\n",
    "\n",
    "#utils\n",
    "from utils import *\n",
    "\n",
    "# linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# plot\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# optimisation\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import LinearConstraint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db85195-fb4b-4d3c-bb77-16a447655821",
   "metadata": {},
   "source": [
    "## Basic manipulation\n",
    "\n",
    "We use `yfinance` to get data, and we store them on csv files for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715056a4-5bae-4851-a3e0-6404ed4bde30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of manipulations\n",
    "stock_name = 'ENI.MI'\n",
    "# Value\n",
    "stock = yf.Ticker(stock_name)\n",
    "stock_info = stock.fast_info\n",
    "# print(stock_info.keys())\n",
    "last_price = stock_info['last_price']\n",
    "sector = stock.info['sector']\n",
    "print(\"market sector: \",sector)\n",
    "previous_close_price = stock_info['regular_market_previous_close']\n",
    "print('market price ', last_price)\n",
    "print('previous close price ', previous_close_price)\n",
    "in_stmt = stock.income_stmt\n",
    "in_stmt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c031401-46a7-47cd-bbf3-9ba7f44eecac",
   "metadata": {},
   "source": [
    "Here we display the time series of dividends of the stock `PXD` over the last 20+ years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591ead26-de5d-45e9-9f22-a2b907ac215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dividends_online(\"PXD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cf5add-b848-480b-bd69-0a98dfe4582a",
   "metadata": {},
   "source": [
    "Here we display the time series of the price evolution of the stock `PXD` over the last 20+ years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1187d1c9-1d10-40b3-90be-4242aac47a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_prices_online(\"PXD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9775f2ef-0bab-4445-badf-b029c1ac737a",
   "metadata": {},
   "source": [
    "## Looking for Stocks and funds\n",
    "\n",
    "Let's start by getting the largest 400 public companies in the US market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52090bda-afe3-4b75-b108-1977ef597a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's extract the 400 tickers\n",
    "names = get_tickers(\"stocks_tickers_sp500.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182b458f-6a9e-4bbc-9143-74d5c7ebaf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the macro data for each stock, like the ROE of the last year, the EBITDA, the industry sector\n",
    "data_df = get_macro_data(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b9b2b9-69b3-469e-a73b-aad4664dfb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D interactive plot\n",
    "px.scatter(data_df[data_df[\"Value\"] > 0], x=\"ROE\", y=\"EBITDA\", size=\"Value\", color = \"Sector\",\n",
    "           hover_data=[\"Name\"], width=1000, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1834643b-1421-4079-b6da-e941aef4d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the largest stocks (top 9) per industry sector\n",
    "selected_data_df, sectors = select_data_per_sector(data_df)\n",
    "selected_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ba3e67-a303-4f58-a442-354ea23cdc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = selected_data_df[\"Name\"].values.tolist()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2890325-953e-4584-ae57-924f0f15e99c",
   "metadata": {},
   "source": [
    "## Load or store data for selected stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4929f12f-15dd-4606-a72d-4ec6aa7f1b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get the price and dividends time series for the selected stocks\n",
    "df_p, df_d = load_or_store_data(names)\n",
    "df_p.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c00b26-323e-461c-973e-2c2662e8a266",
   "metadata": {},
   "source": [
    "## Training and validation data\n",
    "\n",
    "In order to avoid data leakage, we split the time frame we have (almost 40 years!) into six conseqcutive intervals, roughly of the same duration: $40/6 \\sim 7$ years each.\n",
    "\n",
    "This splitting will be used to calibrate the return and correlation matrix (on split $n$ say) and then to make the simulations of the portfolio in the following split ($n+1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecee187-5e52-4fab-89f0-14d6abee0b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â picking one split (7 years for training and 7 following years for validation)\n",
    "splits = pick_a_split(df_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36821a67-a2ce-42c6-bdd6-5582a059ae2c",
   "metadata": {},
   "source": [
    "## Portfolio Optimisation\n",
    "\n",
    "In this section we want to define the optimisation function. The function we use is rathher standard and was discovered by Markovitz in 1954.\n",
    "\n",
    "In short, we want to distribute our wealth to both minimise the risk and maximise the gain of our portfolio.\n",
    "\n",
    "Let's go through the two sides then:\n",
    " 1. **gain** can be both the growth of the stock price $g_p$ (defined as the slope of the regression line) but also it's dividends $g_d = \\sum_t d_t$\n",
    " 2. **risk** is the volatility of a single stock (i.e. its standard deviation). However, we would also consider correlations between stocks time series of the prices. In particular, we would like to avoid getting two very correlated stocks and put a lot of money on both, as we will nott be very protected in case onne on the two falls. The best we can use is the covariance matrix and minimise it.\n",
    " $$ C_{ij} = \\frac{\\sum_t(p_t^i-\\mu^i)(p_t^j-\\mu^j)}{\\sigma_i \\sigma_j}$$\n",
    " \n",
    "Given that $\\bf w$ is the weight vector (i.e. $\\sum_i w_i=1$ and $w_i \\ge 0, \\forall i$), the formula of the optimisation function is:\n",
    "\n",
    "$$ \\mathcal L({\\bf w}) = {\\bf w} \\cdot g_p + {\\bf w} \\cdot g_d + 2 {\\bf w}^T \\cdot C \\cdot {\\bf w} $$\n",
    "\n",
    "The minimisation problem is a constrained misimisation so formulated:\n",
    "$$\\nabla_w \\mathcal L({\\bf w}) = 0,  \\sum_i w_i=1 ,w_i \\ge 0, \\forall i$$\n",
    "\n",
    "The index $i$ runs through the available stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c748482-a4a4-4569-a37d-44f6a5268c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit test\n",
    "cov_mat: np.ndarray = np.array([[1,-1],[-1,2]])  # second is more risky, decorrrelated from first\n",
    "gain: np.ndarray = np.array([0.5,1]) # second gains more\n",
    "gain_div: np.ndarray = np.array([0.01,0.011]) # second gains more\n",
    "# optimisation problem (following the Markovitz model)\n",
    "optimise(portfolio_gain_risk_no_constr, cov_mat, gain, gain_div)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b0a77d-7c97-4f95-8098-83242b847240",
   "metadata": {},
   "source": [
    "## Select a few stocks and for each get the gain and the overall covariance matrix\n",
    "\n",
    "We will now first compute the gains and covariance matrices of some selected stocks (the largest companies per sector), and then use that data to calibrate the loss fuction $\\mathcal L({\\bf w})$ and obtain the portfolio distribution of wealth ${\\bf w}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be26363-3248-4bdf-852e-0fa2ca7aa5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starts from the ticker names selected above\n",
    "\n",
    "gain_div, gain = compute_gains(df_p, df_d, names, splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b5040c-4cf1-4428-b329-9b09565011aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# covariance matrix\n",
    "cov_mat = compute_cov_mat(df_p, names, splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137f67d3-b0fa-4d0f-b7e8-eac0a58b0efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_all = gain\n",
    "gain_div_all = gain_div\n",
    "cov_mat_all = cov_mat\n",
    "# display the covariance matrix\n",
    "fig = px.imshow(cov_mat_all, x=names, y=names, height=800, width=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27d5c8d-5c41-4071-a8fb-7b626221baa2",
   "metadata": {},
   "source": [
    "### Portfolio optimisation specific to each sector\n",
    "\n",
    "We want to run our constrained optimisation on subsets of stocks, in particular, in order to impose a diversification of our portfolio, we will optimise the portfolio in each sector and simply pick the stock where it is suggested to put most bets per sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5e1c86-c565-4f68-b489-31ea1f1ef72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_picks = optimise_per_sector(portfolio_gain_risk_no_constr_with_div, cov_mat_all, gain_all, \n",
    "                                 gain_div_all, sectors, selected_data_df, names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a5dab8-afc4-425a-9735-088171f4f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are teh best picks per sector\n",
    "best_picks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5792e2c0-c994-4572-b1cc-71e0f33b6b48",
   "metadata": {},
   "source": [
    "## Strategy 1: accumulation plan\n",
    "\n",
    "The first strategy we are going to simulate is the accumulation plan. In short, we simulate that ,every 22 working days ( a mmonth roughly) we buy a small amount of stocks (300USD) for 36 months. The hope would be to average out the volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d373e0-995d-4d17-a019-6f5b8bfa7cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's compute the ROIs on the price increase for a portfolio in which we have\n",
    "# put equal amount of money to each one of the top 9 companies per sector\n",
    "\n",
    "rois = []\n",
    "for name in tqdm(names):\n",
    "    _,_, roi = accumulate(df_p,36,300,name,splits)\n",
    "    rois.append(roi)\n",
    "\n",
    "# average gain of the portfolio\n",
    "print(\"Mean ROI:\",np.mean(rois))\n",
    "px.histogram(rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eee8a7-0f62-44d1-9db2-79b7796abca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the results in the validation split\n",
    "list(zip(rois,names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8f75c2-9fae-48bd-80d3-34312522cb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's compute the ROIs on the price increase for a portfolio in which we have\n",
    "# put equal amount of money to each one of the best picks of the previous step\n",
    "\n",
    "rois = []\n",
    "for name in tqdm(best_picks):\n",
    "    _,_, roi = accumulate(df_p,36,300,name,splits)\n",
    "    rois.append(roi)\n",
    "\n",
    "print(\"Mean ROI:\",np.mean(rois))\n",
    "px.histogram(rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b5831-7581-43da-9267-bb6adf08863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results for the best picks in the validation split\n",
    "list(zip(rois,best_picks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8c4e73-a735-4efd-8bf0-29f2adf03b3e",
   "metadata": {},
   "source": [
    "## Strategy 2: dividend reinvestment\n",
    "\n",
    "This other strategy focuses on getting dividends and re-investing such dividends in the same stocks, over and over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b017b-6e18-4e00-bed3-a5753e420321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-optimise taking only dividends into account\n",
    "\n",
    "best_picks = optimise_per_sector(portfolio_gain_risk_no_constr_only_div, cov_mat_all, gain_all, \n",
    "                                 gain_div_all, sectors, selected_data_df, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2addd53c-ba24-4ff4-ad0b-748a4e9689c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's compute the ROIs using this second strategy\n",
    "\n",
    "rois = []\n",
    "for name in tqdm(best_picks):\n",
    "    roi = dividend_reinvest(df_p, df_d, 100, name,splits)\n",
    "    rois.append(roi)\n",
    "\n",
    "print(\"Mean ROI:\",np.mean(rois))\n",
    "px.histogram(rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b277c2ca-e3c4-464f-bd07-d46abdaf8385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results for the dividends strategy on the best picks\n",
    "list(zip(rois,best_picks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0964e03-745a-459d-b7dd-e6c2f716e045",
   "metadata": {},
   "source": [
    "## Benchmarking over all splits\n",
    "\n",
    "We now run a more extensive analysis on all splits to analyse how the portfolio changes over time and also how the ROIs change.\n",
    "\n",
    "Since the dividend reivestment strategy seems more proficient, we will use that one only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9730e0ae-d127-4768-9634-350d9c9e8b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_list = [((0, 1450), (1550, 3099)), \n",
    "               ((1550, 3000), (3100, 4649)), \n",
    "               ((3100, 4550), (4650, 6199)), \n",
    "               ((4650, 6100), (6200, 7749)),\n",
    "               ((6200, 7650), (7750, 9299)), \n",
    "              ]\n",
    "\n",
    "output_print = []\n",
    "\n",
    "for splits in splits_list:\n",
    "    gain_div, gain = compute_gains(df_p, df_d, names,splits)\n",
    "    cov_mat = compute_cov_mat(df_p, names,splits)\n",
    "\n",
    "    gain_all = gain\n",
    "    gain_div_all = gain_div\n",
    "    cov_mat_all = cov_mat\n",
    "\n",
    "    best_picks = optimise_per_sector(portfolio_gain_risk_no_constr_with_div, cov_mat_all, gain_all, \n",
    "                                     gain_div_all, sectors, selected_data_df, names)\n",
    "\n",
    "    rois = []\n",
    "    for name in tqdm(best_picks):\n",
    "        roi = dividend_reinvest(df_p, df_d, 100, name, splits)\n",
    "        rois.append(roi)\n",
    "\n",
    "    output_print.append(\"Mean ROI:\"+ str(np.mean(rois))+ \" for splits:\"+ str(splits)+ \"results: \"+ str(list(zip(rois,best_picks))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3cbd86-7093-4ba5-9401-dff25b00afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## results of the benchmark\n",
    "print(\"\\n\\n\".join(output_print))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85344472-062a-46db-ae06-7c57e1747857",
   "metadata": {},
   "source": [
    "## ETFs analysis\n",
    "\n",
    "Instead of considering stocks, we will now focus o ETFs and only on the 100 largest ones.\n",
    "\n",
    "Also for ETFs, we will first select the top 9 per sector (in this case the sector is where the most of the stocks are) and optimise our portfolio using markovitz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0d9b4e-0991-4373-9b86-66ec14d5df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get etfs tickers\n",
    "names = get_tickers(\"etfs.csv\")\n",
    "print(names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f646ec1a-42d7-4ce4-835c-86c46b6cbc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_etfs = get_macro_etfs(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0744b357-253e-4a35-b2c0-de145ac15fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select best ETF in terms of market cap, per sector\n",
    "data_df, sectors = add_sector_to_etfs(df_etfs)\n",
    "selected_data_df, sectors = select_data_per_sector(data_df)\n",
    "names = selected_data_df[\"Name\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240b2312-d5a2-40ca-be1e-efe875c6806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ETFs time series for prices and dividends\n",
    "df_p, df_d = load_or_store_data(names)\n",
    "df_p.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df74b07-dc51-4136-a459-40551b287d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## benchmark etfs over all time splits\n",
    "splits_list = [((0, 1450), (1550, 3099)), \n",
    "               ((1550, 3000), (3100, 4649)), \n",
    "               ((3100, 4550), (4650, 6199)), \n",
    "               ((4650, 6100), (6200, 7749)),\n",
    "               ((6200, 7650), (7750, 9299)), \n",
    "              ]\n",
    "\n",
    "output_print = []\n",
    "\n",
    "for splits in splits_list:\n",
    "    gain_div, gain = compute_gains(df_p, df_d, names,splits)\n",
    "    cov_mat = compute_cov_mat(df_p, names, splits)\n",
    "\n",
    "    gain_all = gain\n",
    "    gain_div_all = gain_div\n",
    "    cov_mat_all = cov_mat\n",
    "    try:\n",
    "        best_picks = optimise_per_sector(portfolio_gain_risk_no_constr_with_div, cov_mat_all, gain_all, \n",
    "                                         gain_div_all, sectors, selected_data_df, names)\n",
    "\n",
    "        rois = []\n",
    "        for name in tqdm(best_picks):\n",
    "            roi = dividend_reinvest(df_p, df_d, 100, name, splits)\n",
    "            rois.append(roi)\n",
    "\n",
    "        output_print.append(\"Mean ROI:\"+ str(np.mean(rois))+ \" for splits:\"+ str(splits)+ \"results: \"+ str(list(zip(rois,best_picks))))\n",
    "    except ValueError:\n",
    "        print(\"The split does not contain meaningful data (probably too old). Skipping...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0685ec4-c69a-41b9-a817-5a778856239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results of the ETFs benchmarking\n",
    "print(\"\\n\\n\".join(output_print))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3790d72-e7c5-438c-a6ba-f66aba72f531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
